# ðŸ§  AI Personal Workflow Assistant â€“ GuÃ­a de Desarrollo

## ðŸ“‹ Ãndice
- [ðŸ§  AI Personal Workflow Assistant â€“ GuÃ­a de Desarrollo](#-ai-personal-workflow-assistant--guÃ­a-de-desarrollo)
  - [ðŸ“‹ Ãndice](#-Ã­ndice)
  - [ðŸŽ¯ DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
  - [ðŸ“ Estructura del Repositorio](#-estructura-del-repositorio)
  - [âš™ï¸ AutomatizaciÃ³n con Makefile](#ï¸-automatizaciÃ³n-con-makefile)
      - [ðŸ“‹ Comandos disponibles](#-comandos-disponibles)
  - [ðŸ—ºï¸ Hoja de Ruta del Proyecto](#ï¸-hoja-de-ruta-del-proyecto)
    - [âœ… FASE 0: PreparaciÃ³n](#-fase-0-preparaciÃ³n)
    - [ðŸ”§ FASE 1: Backend en FastAPI](#-fase-1-backend-en-fastapi)
    - [ðŸ” FASE 2: IntegraciÃ³n con n8n](#-fase-2-integraciÃ³n-con-n8n)
    - [ðŸ§  FASE 3: Plugins de IA](#-fase-3-plugins-de-ia)
    - [ðŸ“¦ FASE 4: Arquitectura profesional](#-fase-4-arquitectura-profesional)
    - [ðŸ§ª FASE 5: Calidad y preparaciÃ³n para portafolio](#-fase-5-calidad-y-preparaciÃ³n-para-portafolio)
  - [ðŸ—ï¸ Arquitectura del Sistema](#ï¸-arquitectura-del-sistema)
    - [Core Components](#core-components)
    - [CaracterÃ­sticas Implementadas](#caracterÃ­sticas-implementadas)
  - [ðŸ”„ Comandos Ãºtiles](#-comandos-Ãºtiles)
  - [ðŸ§ª Test del backend con curl](#-test-del-backend-con-curl)
  - [âœ¨ Recursos Ãºtiles](#-recursos-Ãºtiles)
  - [ðŸ“Œ Autor](#-autor)
  - [ðŸ› ï¸ Comandos de Desarrollo](#ï¸-comandos-de-desarrollo)
  - [ðŸš€ OptimizaciÃ³n de rendimiento](#-optimizaciÃ³n-de-rendimiento)
    - [Sistema de cachÃ© con Redis](#sistema-de-cachÃ©-con-redis)
    - [OptimizaciÃ³n de Docker](#optimizaciÃ³n-de-docker)
    - [AsincronÃ­a completa](#asincronÃ­a-completa)
    - [Manejo de errores y reintentos](#manejo-de-errores-y-reintentos)
    - [OptimizaciÃ³n de base de datos PostgreSQL](#optimizaciÃ³n-de-base-de-datos-postgresql)
      - [ImplementaciÃ³n de Ã­ndices](#implementaciÃ³n-de-Ã­ndices)
      - [ConfiguraciÃ³n del pool de conexiones](#configuraciÃ³n-del-pool-de-conexiones)
      - [Optimizaciones adicionales](#optimizaciones-adicionales)
  - [ðŸ”§ Troubleshooting](#-troubleshooting)
    - [Problemas Comunes](#problemas-comunes)
  - [ðŸš€ GuÃ­a de ProducciÃ³n](#-guÃ­a-de-producciÃ³n)
    - [Requisitos de Sistema](#requisitos-de-sistema)
    - [ConfiguraciÃ³n de SSL](#configuraciÃ³n-de-ssl)
      - [1. Obtener certificados SSL](#1-obtener-certificados-ssl)
      - [2. ConfiguraciÃ³n en Docker Compose](#2-configuraciÃ³n-en-docker-compose)
      - [3. ConfiguraciÃ³n en FastAPI](#3-configuraciÃ³n-en-fastapi)
      - [4. RedirecciÃ³n de HTTP a HTTPS](#4-redirecciÃ³n-de-http-a-https)
      - [5. RenovaciÃ³n automÃ¡tica de certificados](#5-renovaciÃ³n-automÃ¡tica-de-certificados)
    - [Backup y RecuperaciÃ³n](#backup-y-recuperaciÃ³n)
      - [1. Backup Automatizado de PostgreSQL](#1-backup-automatizado-de-postgresql)
      - [2. Proceso de RecuperaciÃ³n](#2-proceso-de-recuperaciÃ³n)
      - [3. Backup de Flujos de n8n](#3-backup-de-flujos-de-n8n)
  - [ðŸ“Š Monitoreo](#-monitoreo)
    - [MÃ©tricas Clave](#mÃ©tricas-clave)
    - [Herramientas Recomendadas](#herramientas-recomendadas)
  - [ðŸ”„ Actualizaciones y Mejoras](#-actualizaciones-y-mejoras)
    - [UnificaciÃ³n de Modelos de Datos](#unificaciÃ³n-de-modelos-de-datos)
    - [Manejo Robusto de Errores](#manejo-robusto-de-errores)
    - [Limpieza de CÃ³digo Legacy](#limpieza-de-cÃ³digo-legacy)

---

## ðŸŽ¯ DescripciÃ³n del Proyecto

Este proyecto demuestra cÃ³mo construir un sistema de automatizaciÃ³n inteligente basado en IA, utilizando un backend modular y flujos orquestados desde `n8n`.

Este proyecto integra automatizaciones con inteligencia artificial usando:
- `n8n` como orquestador de flujos
- `FastAPI` como backend inteligente
- IA para tareas como resumen de textos, clasificaciÃ³n, generaciÃ³n de reportes, etc.
- Notificaciones en Telegram, emails o dashboards
- Persistencia en PostgreSQL para trazabilidad y anÃ¡lisis
- ContenerizaciÃ³n profesional con Docker

---


## ðŸ“ Estructura del Repositorio

```bash
AI-Workflow-Assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ router.py       # Router principal
â”‚   â”‚   â”œâ”€â”€ workflow_endpoints.py # Endpoints principales
â”‚   â”‚   â””â”€â”€ schemas.py         # Esquemas Pydantic
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ errors.py          # Manejo de errores y excepciones globales
â”‚   â”‚   â”œâ”€â”€ health.py          # Health checks unificados
â”‚   â”‚   â”œâ”€â”€ logging.py         # ConfiguraciÃ³n centralizada de logs
â”‚   â”‚   â””â”€â”€ cache.py           # Sistema de cachÃ© con Redis
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ db.py              # GestiÃ³n unificada de base de datos
â”‚   â”‚   â”œâ”€â”€ models.py          # Modelos SQLAlchemy unificados (ConsultaIA, EstadoUsuario)
â”‚   â”‚   â””â”€â”€ tasks/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ summarize.py   # Servicio de resumen con manejo de errores
â”‚   â”‚       â”œâ”€â”€ translate.py   # Servicio de traducciÃ³n con manejo de errores
â”‚   â”‚       â””â”€â”€ classify.py    # Servicio de clasificaciÃ³n con manejo de errores
â”‚   â”œâ”€â”€ migrations/            # Migraciones de base de datos
â”‚   â”œâ”€â”€ main.py                # Punto de entrada con handler de excepciones global
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ GUIDE.md
â”‚   â””â”€â”€ workflow.md            # DocumentaciÃ³n tÃ©cnica
â””â”€â”€ ... existing files ...
```


## âš™ï¸ AutomatizaciÃ³n con Makefile

Se incluye un `Makefile` para automatizar tareas de desarrollo y testing:

#### ðŸ“‹ Comandos disponibles

| Comando         | DescripciÃ³n                                     |
|-----------------|-------------------------------------------------|
| `make up`       | Levanta backend, PostgreSQL y n8n con Docker    |
| `make down`     | Detiene los contenedores                        |
| `make build`    | Reconstruye la imagen del backend               |
| `make restart`  | Reinicia el backend con build                   |
| `make logs`     | Muestra logs en tiempo real del backend         |
| `make ps`       | Lista los contenedores en ejecuciÃ³n             |
| `make db`       | Accede al cliente `psql` dentro del contenedor  |
| `make reset-db` | Elimina volumen de datos de PostgreSQL (âš ï¸)     |
| `make clean`    | Limpia archivos temporales y cachÃ©              |
| `make test`     | Ejecuta tests del backend                       |
| `make help`     | Muestra la lista de comandos disponibles        |

## ðŸ—ºï¸ Hoja de Ruta del Proyecto

### âœ… FASE 0: PreparaciÃ³n
- [x] Crear repositorio Git (estructura base arriba)
- [x] Tener un VPS o servidor (Google Cloud, local, etc.)
- [x] Tener Docker y Docker Compose configurados
- [x] Tener instalado y accesible `n8n` en dominio o subdominio

---

### ðŸ”§ FASE 1: Backend en FastAPI
- [x] Crear API bÃ¡sica con FastAPI
- [x] Implementar endpoints principales para procesamiento de texto
- [x] Definir estructura de peticiones/respuestas con Pydantic
- [x] AÃ±adir procesamiento con OpenAI para tareas de IA
- [x] Testear localmente los endpoints

---

### ðŸ” FASE 2: IntegraciÃ³n con n8n
- [x] Crear flujo en n8n que reciba documentos por Webhook
- [x] Enviar texto al backend para procesar
- [x] Recibir y parsear la respuesta para:
  - [x] Enviar mensaje a Telegram o email
  - [x] Guardar en base de datos (opcional)
  - [x] Registrar en Google Sheets
- [x] Exportar el flujo a `n8n-flows/` como JSON
- [x] Configurar correctamente el webhook con ngrok usando `WEBHOOK_URL` para evitar puertos no permitidos por Telegram
- [x] Validar que el bot de Telegram activa correctamente el Trigger en n8n

---

### ðŸ§  FASE 3: Plugins de IA
- [x] `summarize`: resumen de texto largo
- [x] `classify`: detecciÃ³n de intenciÃ³n o urgencia
- [x] `translate`: traducir texto
- [ ] `extract`: extracciÃ³n de entidades clave (personas, fechas, nÃºmeros)
- [ ] `report`: generaciÃ³n de resumen semanal (integraciÃ³n con Google Calendar opcional)
- [ ] `generate`: generaciÃ³n de texto o informes

---

### ðŸ“¦ FASE 4: Arquitectura profesional
- [x] Dockerizar backend + postgree en `docker-compose.yml`
- [x] Estructura modular profesional (con /api, /services, /core)
- [x] Habilitar logging y trazabilidad centralizada
- [x] AÃ±adir health checks unificados
- [x] Persistencia con PostgreSQL
- [x] DocumentaciÃ³n OpenAPI en `/docs`
- [x] Seguridad con API Key en el backend
- [x] Manejo robusto de errores
- [x] UnificaciÃ³n de modelos de base de datos
- [ ] AutenticaciÃ³n JWT (pendiente)
- [x] Endpoint para consultar histÃ³rico

---

### ðŸ§ª FASE 5: Calidad y preparaciÃ³n para portafolio
- [x] AÃ±adir ejemplos reales de uso
- [ ] Capturas de pantalla o vÃ­deo demo
- [x] README completo con descripciÃ³n, arquitectura, instrucciones de uso
- [ ] Despliegue real en dominio propio (por ejemplo: `assistant.dasafodata.com`)
- [ ] Preparar presentaciÃ³n en LinkedIn y demo pÃºblica

---

## ðŸ—ï¸ Arquitectura del Sistema

### Core Components
1. **API Layer** (`/api/routes/`)
   - Endpoints REST para interacciÃ³n con el sistema
   - ValidaciÃ³n de API keys
   - Manejo de errores centralizado

2. **Core Layer** (`/core/`)
   - Schemas de datos (Pydantic)
   - Logging centralizado
   - Health checks
   - Sistema de cachÃ© con Redis
   - Manejo global de excepciones

3. **Services Layer** (`/services/`)
   - Tareas de IA con manejo robusto de errores
   - Persistencia unificada en `ConsultaIA`
   - LÃ³gica de negocio

### CaracterÃ­sticas Implementadas
- Logging centralizado y consistente
- Health checks unificados
- Variables de entorno centralizadas
- Seguridad bÃ¡sica con API keys
- Schemas validados con Pydantic
- Persistencia unificada en PostgreSQL
- Manejo robusto de errores con cÃ³digos HTTP especÃ­ficos
- CachÃ© con Redis para optimizar rendimiento

---

## ðŸ”„ Comandos Ãºtiles
``` bash
# Levantar los servicios
docker compose up -d
make up # usando makefile

# Reconstruir backend tras cambios en dependencias
docker compose build backend
make build # usando makefile

# Parar y eliminar contenedores
docker compose down
make stop # usando makefile

# Ver logs en tiempo real del backend
docker compose logs -f backend
make logs # usando makefile

# Limpiar archivos temporales
make clean
```

## ðŸ§ª Test del backend con curl
``` bash
# Gestionar estado/modo de un usuario
curl -X POST http://localhost:8000/api/v1/estado \
  -H "Content-Type: application/json" \
  -H "x-api-key: ${API_KEY}" \
  -d '{
    "chat_id": 123456789,
    "modo": "/resumir"
  }'

# Procesar texto (resumir, traducir, clasificar)
curl -X POST http://localhost:8000/api/v1/procesar \
  -H "Content-Type: application/json" \
  -H "x-api-key: ${API_KEY}" \
  -d '{
    "chat_id": 123456789,
    "texto": "Texto que serÃ¡ procesado segÃºn el tipo de tarea especificado...",
    "tipo_tarea": "resumir"
  }'

# Consultar historial de operaciones
curl -X POST http://localhost:8000/api/v1/consultar \
  -H "Content-Type: application/json" \
  -H "x-api-key: ${API_KEY}" \
  -d '{
    "chat_id": 123456789,
    "tipo_tarea": "traducir",
    "limit": 5
  }'

# Consulta en lenguaje natural del historial
curl -X POST http://localhost:8000/api/v1/consultar-inteligente \
  -H "Content-Type: application/json" \
  -H "x-api-key: ${API_KEY}" \
  -d '{
    "chat_id": 123456789,
    "texto": "MuÃ©strame mis Ãºltimos resÃºmenes"
  }'

# Verificar estado del sistema
curl http://localhost:8000/health
```

## âœ¨ Recursos Ãºtiles

- [n8n Documentation](https://docs.n8n.io)
- [FastAPI Docs](https://fastapi.tiangolo.com)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [Langchain (opcional)](https://python.langchain.com)

---

## ðŸ“Œ Autor
David â€“ dasafodata | Zaragoza, EspaÃ±a  
Contacto: [dasafodata.com](https://dasafodata.com)

---

## ðŸ› ï¸ Comandos de Desarrollo

```bash
# Inicializar proyecto
cp .env.example .env
make build

# Desarrollo
make up           # Iniciar servicios
make logs        # Ver logs
make ps          # Estado de contenedores

# Testing
make test        # Ejecutar tests
make health-check # Verificar estado

# Database
make db          # Acceder a PostgreSQL
make reset-db    # Reset DB (âš ï¸ cuidado)

# Limpieza
make clean       # Eliminar archivos temporales y cachÃ©
```

## ðŸš€ OptimizaciÃ³n de rendimiento

### Sistema de cachÃ© con Redis

El proyecto ahora incluye un sistema de cachÃ© utilizando Redis para optimizar las consultas frecuentes a la API de OpenAI:

- **ReducciÃ³n de costos**: Al cachear respuestas similares, se reduce el nÃºmero de llamadas a la API.
- **Mejora de velocidad**: Las respuestas cacheadas se entregan instantÃ¡neamente, sin esperar a la API.
- **ConfiguraciÃ³n flexible**: Tiempos de vida (TTL) configurables por cada tipo de tarea.

Para configurar el sistema de cachÃ©, ajusta las siguientes variables en tu archivo `.env`:

```bash
# Redis - Sistema de cachÃ©
REDIS_HOST=redis           # Host del servidor Redis
REDIS_PORT=6379            # Puerto de Redis
REDIS_DB=0                 # Base de datos Redis
REDIS_CACHE_TTL=86400      # TTL general (24h)
SUMMARY_CACHE_TTL=86400    # TTL para resÃºmenes
TRANSLATION_CACHE_TTL=86400  # TTL para traducciones
CLASSIFICATION_CACHE_TTL=86400  # TTL para clasificaciones
```

Para limpiar la cachÃ© en casos necesarios, puedes aÃ±adir un nuevo endpoint en el futuro o reiniciar el contenedor de Redis:

```bash
# Reiniciar sÃ³lo Redis
docker restart ai-workflow-redis
```

### OptimizaciÃ³n de Docker

El proyecto ahora utiliza una imagen Docker mÃ¡s eficiente y ligera mediante:

- **Multi-stage builds**: Separamos la fase de compilaciÃ³n de la imagen final para reducir el tamaÃ±o.
- **Alpine como base**: Usamos Alpine Linux para una imagen mÃ¡s pequeÃ±a (aprox. 70% de reducciÃ³n).
- **Wheels pre-compilados**: Las dependencias se compilan en la primera fase y solo se instalan los binarios en la imagen final.

Beneficios de estas optimizaciones:

- **Menor tamaÃ±o de imagen**: De ~1GB con slim a ~300MB con Alpine y multi-stage.
- **Despliegue mÃ¡s rÃ¡pido**: Menor tiempo de descarga y arranque de contenedores.
- **Mayor seguridad**: Superficie de ataque reducida al incluir menos componentes.

Para reconstruir la imagen con estas optimizaciones:

```bash
# Reconstruir la imagen del backend
make build

# O manualmente
docker-compose build backend
```

### AsincronÃ­a completa

El backend ahora implementa asincronÃ­a completa en todos sus componentes:

- **SQLAlchemy 2.0 Async**: Conexiones asÃ­ncronas a base de datos para mejor rendimiento.
- **AsyncOpenAI**: Cliente asÃ­ncrono para las llamadas a la API de OpenAI.
- **Operaciones asÃ­ncronas**: Todas las operaciones de I/O son asÃ­ncronas (DB, API, cachÃ©).

Beneficios de la asincronÃ­a:

- **Mayor concurrencia**: Permite manejar mÃºltiples solicitudes simultÃ¡neas sin bloquear hilos.
- **Mejor rendimiento**: Aprovecha eficientemente los tiempos de espera de I/O.
- **Escalabilidad**: La aplicaciÃ³n puede manejar mÃ¡s carga con los mismos recursos.

Para entender el modelo asÃ­ncrono, observa cÃ³mo se definen y utilizan las funciones:

```python
# Ejemplo de funciÃ³n asÃ­ncrona
@cache_response(ttl=86400)
async def run(input: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    response = await client.chat.completions.create(...)
    await guardar_consulta(...)
    return {...}
```

Todos los endpoints ahora son asÃ­ncronos, lo que mejora significativamente el rendimiento general de la aplicaciÃ³n.

### Manejo de errores y reintentos

El sistema ahora incluye un manejo de errores robusto y un mecanismo de reintentos automÃ¡ticos:

- **Errores estructurados**: Sistema de errores estandarizado con cÃ³digos, mensajes descriptivos y detalles.
- **Reintentos automÃ¡ticos**: Las llamadas a OpenAI se reintentan automÃ¡ticamente ante fallos temporales.
- **Backoff exponencial**: Tiempo creciente entre reintentos para evitar sobrecargar servicios externos.
- **Jitter aleatorio**: Previene tormentas de reintentos sincronizados en entornos multiusuario.
- **CÃ³digos HTTP especÃ­ficos**: 504 para timeouts, 429 para rate limits y 502 para errores de API.

El sistema de reintentos se implementa mediante un decorador que se puede aplicar a cualquier funciÃ³n asÃ­ncrona:

```python
@with_retry
async def call_openai_with_retry(text: str):
    # Esta funciÃ³n se reintentarÃ¡ automÃ¡ticamente si falla
    response = await client.chat.completions.create(...)
    return response
```

Beneficios del sistema de errores y reintentos:

- **Mayor fiabilidad**: El sistema es resiliente ante fallos temporales de red o servicios.
- **Mejor diagnÃ³stico**: Los errores incluyen cÃ³digos estandarizados y detalles para facilitar la soluciÃ³n.
- **Mensajes coherentes**: Los usuarios reciben informaciÃ³n clara sobre los problemas.
- **Logs mejorados**: Cada error se registra con su cÃ³digo, mensaje y stack trace para facilitar depuraciÃ³n.

Para configurar los reintentos, ajusta estas variables en el `.env`:

```bash
# ConfiguraciÃ³n de reintentos
OPENAI_TIMEOUT=30.0          # Timeout en segundos
OPENAI_MAX_RETRIES=3         # NÃºmero mÃ¡ximo de reintentos
OPENAI_RETRY_DELAY_BASE=1.0  # Retraso base (segundos)
OPENAI_RETRY_DELAY_MAX=10.0  # Retraso mÃ¡ximo (segundos)
OPENAI_RETRY_JITTER=0.1      # Factor de aleatoriedad
```

### OptimizaciÃ³n de base de datos PostgreSQL

#### ImplementaciÃ³n de Ã­ndices

La aplicaciÃ³n utiliza Ã­ndices estratÃ©gicos para mejorar significativamente el rendimiento de consultas frecuentes:

```sql
-- Ãndices en la tabla unificada consultas_ia
CREATE INDEX idx_consultas_chat_id ON consultas_ia(chat_id);
CREATE INDEX idx_consultas_tipo_tarea ON consultas_ia(tipo_tarea);
CREATE INDEX idx_consultas_fecha ON consultas_ia(fecha);

-- Ãndice combinado para bÃºsquedas comunes
CREATE INDEX idx_consultas_chat_tipo ON consultas_ia(chat_id, tipo_tarea);
```

Estos Ã­ndices se aplican automÃ¡ticamente durante la inicializaciÃ³n de la base de datos mediante los scripts de migraciÃ³n en `./backend/migrations`.

#### ConfiguraciÃ³n del pool de conexiones

El sistema implementa un pool de conexiones optimizado para equilibrar rendimiento y recursos:

```python
# En backend/services/db.py
async def get_db_pool():
    engine = create_async_engine(
        DATABASE_URL,
        echo=False,
        pool_size=20,               # TamaÃ±o base del pool
        max_overflow=10,            # Conexiones adicionales permitidas
        pool_timeout=30,            # Tiempo de espera para obtener conexiÃ³n
        pool_recycle=1800,          # Reciclar conexiones cada 30 min
        pool_pre_ping=True,         # Verificar conexiones antes de usarlas
        pool_use_lifo=True,         # Estrategia LIFO para mejor reutilizaciÃ³n
    )
    return engine
```

Para configurar estos parÃ¡metros segÃºn tus necesidades, ajusta las siguientes variables en `.env`:

```bash
# ConfiguraciÃ³n pool de PostgreSQL
POSTGRES_POOL_SIZE=20
POSTGRES_MAX_OVERFLOW=10
POSTGRES_POOL_TIMEOUT=30
POSTGRES_POOL_RECYCLE=1800
```

#### Optimizaciones adicionales

- **Vacuum automÃ¡tico**: Configurado para ejecutarse periÃ³dicamente y mantener la base de datos optimizada
- **Statement timeout**: Limita la duraciÃ³n mÃ¡xima de consultas para evitar bloqueos prolongados
- **Particionamiento**: Para tablas que crecen significativamente (implementado en `consultas_ia` por fecha)

Para aplicar estas optimizaciones en un entorno de producciÃ³n, utiliza:

```bash
# Aplicar optimizaciones de PostgreSQL
make optimize-db
```

## ðŸ”§ Troubleshooting

### Problemas Comunes
1. **Redis Port in Use**
   ```bash
   # SoluciÃ³n 1: Cambiar puerto
   REDIS_PORT=6380
   
   # SoluciÃ³n 2: Detener Redis local
   sudo service redis-server stop
   ```

2. **Database Connection Issues**
   ```bash
   # Verificar que el contenedor de PostgreSQL estÃ¡ corriendo
   docker ps | grep ai-workflow-db
   
   # Verificar logs de PostgreSQL
   docker logs ai-workflow-db
   
   # Reiniciar el contenedor
   docker restart ai-workflow-db
   ```

3. **API Key Problems**
   ```bash
   # Verificar que API_KEY estÃ¡ correctamente configurada en .env
   grep API_KEY .env
   
   # Asegurarse de que el header se estÃ¡ enviando correctamente
   curl -v -H "x-api-key: TU_API_KEY" http://localhost:8000/health
   ```

4. **Errores de OpenAI API**
   ```bash
   # Verificar errores 429 (rate limit)
   grep "status_code=429" backend/logs/app.log
   
   # Verificar errores 504 (timeout)
   grep "status_code=504" backend/logs/app.log
   
   # Verificar la validez de tu API Key
   echo $OPENAI_API_KEY | grep "sk-"
   ```

## ðŸš€ GuÃ­a de ProducciÃ³n

### Requisitos de Sistema
- CPU: 2+ cores
- RAM: 4GB mÃ­nimo
- Disco: 20GB SSD

### ConfiguraciÃ³n de SSL

Para asegurar la comunicaciÃ³n con el sistema en producciÃ³n, es necesario configurar SSL/TLS:

#### 1. Obtener certificados SSL

```bash
# Usando Certbot (Let's Encrypt)
sudo apt-get update
sudo apt-get install certbot
sudo certbot certonly --standalone -d tu-dominio.com -d www.tu-dominio.com
```

#### 2. ConfiguraciÃ³n en Docker Compose

AÃ±ade los siguientes volÃºmenes en el servicio de backend en `docker-compose.yml`:

```yaml
services:
  backend:
    # ... configuraciÃ³n existente ...
    volumes:
      - /etc/letsencrypt/live/tu-dominio.com/fullchain.pem:/app/certs/fullchain.pem:ro
      - /etc/letsencrypt/live/tu-dominio.com/privkey.pem:/app/certs/privkey.pem:ro
```

#### 3. ConfiguraciÃ³n en FastAPI

En el archivo `main.py`, configura el servidor con SSL:

```python
import uvicorn

if __name__ == "__main__":
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        ssl_keyfile="/app/certs/privkey.pem",
        ssl_certfile="/app/certs/fullchain.pem"
    )
```

#### 4. RedirecciÃ³n de HTTP a HTTPS

Para forzar el uso de HTTPS, puede aÃ±adir un middleware en FastAPI:

```python
@app.middleware("http")
async def redirect_to_https(request, call_next):
    if request.url.scheme == "http":
        https_url = request.url.replace(scheme="https")
        return RedirectResponse(url=str(https_url))
    
    return await call_next(request)
```

#### 5. RenovaciÃ³n automÃ¡tica de certificados

Configurar un cron job para renovar automÃ¡ticamente los certificados:

```bash
# AÃ±adir a crontab
echo "0 3 * * * certbot renew --quiet && docker restart ai-workflow-assistant-backend" | sudo tee -a /etc/crontab
```

### Backup y RecuperaciÃ³n

La estrategia de backup y recuperaciÃ³n asegura la integridad y disponibilidad de los datos del sistema:

#### 1. Backup Automatizado de PostgreSQL

Configure backups diarios con el siguiente script:

```bash
#!/bin/bash
# /usr/local/bin/backup-ai-workflow.sh

TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_DIR="/var/backups/ai-workflow"
CONTAINER="ai-workflow-postgres"
DB_USER="postgres"
DB_NAME="workflow"

# Crear directorio si no existe
mkdir -p $BACKUP_DIR

# Ejecutar backup
docker exec $CONTAINER pg_dump -U $DB_USER -d $DB_NAME | gzip > "$BACKUP_DIR/db_backup_$TIMESTAMP.sql.gz"

# Retener solo los Ãºltimos 7 dÃ­as
find $BACKUP_DIR -name "db_backup_*.sql.gz" -type f -mtime +7 -delete
```

Configure cron para ejecutar diariamente:

```bash
# AÃ±adir a crontab
sudo chmod +x /usr/local/bin/backup-ai-workflow.sh
echo "0 2 * * * /usr/local/bin/backup-ai-workflow.sh" | sudo tee -a /etc/crontab
```

#### 2. Proceso de RecuperaciÃ³n

Para restaurar desde un backup:

```bash
# Restaurar desde un backup especÃ­fico
gunzip -c /var/backups/ai-workflow/db_backup_20240101_020000.sql.gz | docker exec -i ai-workflow-postgres psql -U postgres -d workflow
```

#### 3. Backup de Flujos de n8n

Configure backups automÃ¡ticos de los flujos de n8n:

```bash
# Exportar flujos a archivos JSON (desde n8n)
curl -X GET "http://localhost:5678/rest/workflows" \
  -H "x-n8n-api-key: $N8N_API_KEY" \
  > /var/backups/ai-workflow/n8n_workflows_$(date +"%Y%m%d").json
```

## ðŸ“Š Monitoreo

### MÃ©tricas Clave

El monitoreo efectivo del sistema ayuda a garantizar un rendimiento Ã³ptimo y a detectar problemas antes de que afecten a los usuarios:

1. **MÃ©tricas de Servicio**:
   - Tiempo de respuesta (promedio, p95, p99)
   - Tasa de solicitudes (RPS)
   - Tasa de errores (5xx, 4xx)
   - Tiempo de procesamiento por tipo de tarea

2. **MÃ©tricas de Recursos**:
   - Uso de CPU y memoria
   - Uso de disco y operaciones I/O
   - Conexiones de red
   - UtilizaciÃ³n de pool de conexiones DB

3. **MÃ©tricas de AplicaciÃ³n**:
   - Tasa de hit/miss de cachÃ©
   - Latencia de llamadas a OpenAI
   - NÃºmero de reintentos
   - Errores por tipo de tarea

4. **MÃ©tricas de Negocio**:
   - Tareas procesadas por hora/dÃ­a
   - DistribuciÃ³n por tipo de tarea
   - Usuarios activos
   - Tiempo de procesamiento promedio

### Herramientas Recomendadas

1. **Monitoreo de Infraestructura**:
   - **Prometheus**: RecolecciÃ³n de mÃ©tricas y alertas
   - **Grafana**: VisualizaciÃ³n de dashboards
   - **Node Exporter**: MÃ©tricas del sistema
   - **cAdvisor**: MÃ©tricas de contenedores
   - **AlertManager**: GestiÃ³n de alertas

2. **ConfiguraciÃ³n BÃ¡sica de Prometheus**:

   Crear `prometheus.yml`:
   ```yaml
   global:
     scrape_interval: 15s
   
   scrape_configs:
     - job_name: 'backend'
       static_configs:
         - targets: ['backend:8000']
     
     - job_name: 'node'
       static_configs:
         - targets: ['node-exporter:9100']
     
     - job_name: 'cadvisor'
       static_configs:
         - targets: ['cadvisor:8080']
   ```

3. **Agregar servicios de monitoreo al docker-compose.yml**:

   ```yaml
   services:
     prometheus:
       image: prom/prometheus:latest
       volumes:
         - ./prometheus.yml:/etc/prometheus/prometheus.yml
         - prometheus_data:/prometheus
       ports:
         - "9090:9090"
     
     grafana:
       image: grafana/grafana:latest
       volumes:
         - grafana_data:/var/lib/grafana
       ports:
         - "3000:3000"
       depends_on:
         - prometheus
     
     node-exporter:
       image: prom/node-exporter:latest
       ports:
         - "9100:9100"
       restart: always
   
   volumes:
     prometheus_data:
     grafana_data:
   ```

4. **Dashboards Esenciales**:
   - Rendimiento general del sistema
   - MÃ©tricas de API por endpoint
   - Uso de recursos por contenedor
   - Rendimiento de base de datos
   - Errores y tiempos de respuesta

5. **Alertas Recomendadas**:
   - Tiempo de respuesta > 2 segundos
   - Tasa de error > 1%
   - Uso de CPU > 80%
   - Uso de memoria > 85%
   - Redis o PostgreSQL no responden
   - Espacio en disco < 10%

## ðŸ”„ Actualizaciones y Mejoras

### UnificaciÃ³n de Modelos de Datos

Hemos realizado una consolidaciÃ³n significativa en los modelos de datos, eliminando clases antiguas y adoptando un enfoque mÃ¡s unificado:

- **Modelo Unificado**: Se ha reemplazado los modelos separados (`Resumen`, `Traduccion`, `Clasificacion`) por un Ãºnico modelo `ConsultaIA` que almacena todas las consultas.
- **Estructura optimizada**: El nuevo modelo incluye un campo `tipo_tarea` que identifica el tipo de operaciÃ³n, y campos unificados para almacenar texto original y resultado.
- **Ãndices mejorados**: Se han aÃ±adido Ã­ndices para optimizar las consultas frecuentes sobre `chat_id`, `tipo_tarea` y `fecha`.

Beneficios de la unificaciÃ³n:
- **CÃ³digo mÃ¡s simple**: LÃ³gica centralizada para persistencia de datos
- **Consultas mÃ¡s eficientes**: Una sola tabla para consultar todo el historial
- **Mantenimiento mÃ¡s sencillo**: Estructura de datos coherente y predecible
- **EvoluciÃ³n facilitada**: AÃ±adir nuevas tareas no requiere nuevas tablas

El modelo actual se define asÃ­:

```python
class ConsultaIA(Base):
    __tablename__ = "consultas_ia"

    id = Column(Integer, primary_key=True)
    chat_id = Column(BigInteger, nullable=False, index=True)
    tipo_tarea = Column(String(50), nullable=False, index=True)  # 'resumir', 'clasificar', etc.
    texto_original = Column(Text, nullable=False)
    resultado = Column(Text)
    idioma = Column(String(20), nullable=True)  # Solo para traducciones
    fecha = Column(DateTime(timezone=True), server_default=func.now(), index=True)
```

### Manejo Robusto de Errores

Hemos implementado un sistema de manejo de errores mucho mÃ¡s robusto:

- **Tipos especÃ­ficos de errores**: 
  - `OpenAITimeoutError`: Para timeouts de conexiÃ³n (HTTP 504)
  - `OpenAIRateLimitError`: Para lÃ­mites de tasa excedidos (HTTP 429)
  - `OpenAIError`: Para otros errores de la API (HTTP 502)

- **Manejo global de excepciones**: AÃ±adido un manejador global que captura todas las excepciones no controladas y devuelve respuestas HTTP apropiadas.

- **Reintentos inteligentes**: Sistema de reintentos con backoff exponencial que reduce la carga en la API y mejora la fiabilidad.

- **Logging mejorado**: Registro detallado de excepciones con toda la informaciÃ³n necesaria para el diagnÃ³stico.

Este sistema garantiza que los usuarios reciban mensajes claros cuando ocurren problemas, y que el equipo tÃ©cnico disponga de toda la informaciÃ³n necesaria para diagnosticar y resolver problemas rÃ¡pidamente.

### Limpieza de CÃ³digo Legacy

Se ha realizado una importante limpieza de cÃ³digo legacy:

- **EliminaciÃ³n de modelos antiguos**: Se han eliminado las clases `Resumen`, `Traduccion` y `Clasificacion` que ya no se utilizaban.

- **Limpieza del Makefile**: Se han comentado o eliminado referencias a endpoints que no existen en el cÃ³digo, como `/api/v1/mcp/invoke`.

- **EliminaciÃ³n de migraciones obsoletas**: Archivos de migraciÃ³n obsoletos como `003_migrate_legacy_to_unified.sql` y `02_migrate_legacy_to_unified.sql` han sido eliminados.

- **ActualizaciÃ³n de documentaciÃ³n**: Tanto el README como esta guÃ­a se han actualizado para reflejar con precisiÃ³n el estado actual del proyecto.

Estas limpiezas ayudan a mantener el cÃ³digo mÃ¡s mantenible y comprensible, eliminando fuentes potenciales de confusiÃ³n para los desarrolladores que trabajen en el proyecto en el futuro.